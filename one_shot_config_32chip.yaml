# 32-chip configuration
defaults:
  - _self_

data:
  num_shots: 1
  duplicate_factor: 128
  train_dataset: one_shot_rlvr
  train_split: pi1
  test_dataset: math500
  test_split: test
  batch_size: 128
  max_prompt_length: 1024
  num_test_batches: 100
  train_data_dir: "./data/train"
  test_data_dir: "./data/test"

model:
  name: 'qwen2.5-1.5b'
  # CRITICAL: 32 chips = 4 hosts Ã— 8 chips
  # Use 4-way FSDP (data parallel across hosts) and 8-way TP (tensor parallel within host)
  mesh_config: '[[4, 8], ["fsdp", "tp"]]'
  use_gradient_checkpointing: true
  actor_dtype: 'float32'
  reference_dtype: 'float32'
  rollout_dtype: 'float32'
  dtype: 'float32'

algorithm:
  total_generation_steps: 1024
  temperature: 0.6
  top_p: 1.0
  top_k: null
  num_generations: 8
  num_iterations: 1
  beta: 0.001
  epsilon: 0.2

trainer:
  val_before_train: false
  learning_rate: 1e-6
  b1: 0.9
  b2: 0.999
  weight_decay: 0.1
  warmup_steps_ratio: 0.0
  max_grad_norm: 0.1
  num_batches: 1
  total_epochs: 20
  gradient_accumulation_steps: 1
  save_freq: 40
  max_to_keep: 1
  test_freq: 20
  checkpoint_dir: "./checkpoints/one_shot_rlvr/"
  intermediate_ckpt_dir: "./intermediate_ckpt/"
  metrics_log_dir: "./logs/tensorboard/one_shot_rlvr/"
  tensorboard_port: 6006

memory:
  clear_cache_between_steps: true
  enable_memory_efficient_attention: true
  cpu_offload_reference_model: true

experiment:
  name: "one_shot_rlvr_32chip"
  description: "One-Shot RLVR on 32 chips"
  tags: ["one-shot", "rlvr", "32-chip"]
